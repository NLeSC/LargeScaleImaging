% ********************************************************************
% *                  Format for IMVIP 2017  papers,                  *
% *         based on the IMVIP 2001, 2006, 2014-2016 templates       *
% ********************************************************************
\documentclass[a4paper,11pt]{article}



\setlength{\topmargin}{-0.5cm}
\setlength{\headsep}{.5cm}
%\setlength{\footskip}{1.0cm}
\setlength{\textheight}{24cm}
\setlength{\textwidth}{17cm}
\setlength{\evensidemargin}{-.5cm}
\setlength{\oddsidemargin}{-.5cm}



\usepackage{fourier}
\usepackage{color}
\usepackage{graphicx}
 \graphicspath{{./Figs/}}
 \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\usepackage{url}
\usepackage[affil-it]{authblk}
\usepackage{amsmath}
\usepackage{wrapfig}
\usepackage{xspace}

\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{verbatim}
\usepackage{subcaption}

\pagestyle{empty}

%%%%
\begin{document}

\title{Shape and Moment Invariants Local Descriptor for Structured Images}

\author{Anonymous Submission}
\affil{Anonymous Affiliation}

%\author{Elena Ranguelova}
%\affil{Netherlands eScience Centre\\ Amsterdam, The Netherlands.}
\date{}
\maketitle
\thispagestyle{empty}



\begin{abstract}
Finding correspondences between two images to determine if they depict the same scene or object, is a fundamental, yet challenging task. To cope with different viewpoints and lighting conditions, usually salient regions are detected as local invariant features, encoded by descriptors such as SIFT or SURF. While using the image intensities around a single point, the centroid of the region, to compute a histogram-of-gradients type descriptor, often works well, we argue that for structured scenes it is enough to use only the binary shape of the regions. We propose a $20$-dimensional Shape and Moment Invariant (SMI) descriptor and show that it outperforms the $64$-dimensional SURF on classical and transformation-independent datasets in terms of precision, achieving similar or even higher accuracy, while having a better scalability.
\end{abstract}
\textbf{Keywords:} image matching, affine-invariant descriptor, shape invariants, moment invariants



%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

\begin{wrapfigure}{r}{0.5\textwidth}
 \vspace{-22pt} 
\begin{center}
%\begin{subfigure}[b]{0.247\textwidth}
\begin{subfigure}[b]{0.22\textwidth}
  \includegraphics[width=\textwidth, height=\textwidth]{cool_car_scale5}
\end{subfigure}
%\begin{subfigure}[b]{0.247\textwidth}
\begin{subfigure}[b]{0.22\textwidth}
\includegraphics[width=\textwidth]{cool_car_viewpoint5}
\end{subfigure}
\end{center}
\vspace{-22pt}
\begin{center}
%\begin{subfigure}[b]{0.247\textwidth}
\begin{subfigure}[b]{0.22\textwidth}
  \includegraphics[width=\textwidth]{1graffiti_blur4}
\end{subfigure}
%\begin{subfigure}[b]{0.247\textwidth}
\begin{subfigure}[b]{0.22\textwidth}
\includegraphics[width=\textwidth]{2freiburg_center_blur4}
\end{subfigure}
\end{center}
\vspace{-20pt}
\caption{\small ``Is it the same object or scene?'' Matching two images under different transformation using MSER regions.\\ {\em Top image pair} (scale and viewpoint): SURF descriptor yields false negative (similarity score $0.096$), while SMI - true positive ($0.89$).
{\em Bottom image pair} (blur): SURF gives false positive ($0.27$), while SMI - true negative ($-0.11$).}
  \vspace{-16pt}
\end{wrapfigure}\label{fig:intro1}

Automatically determining weather $2$ images depict partially the same physical scene is a fundamental computer vision problem such as baseline stereo matching, image retrieval, etc.~\cite{EscaleraCVPR07,Matas2002BMVC}). {\em Detection} of local (due to partial overlap) image features, followed by their {\em description}, is a classical approach. Salient regions, corresponding to the same image patches, detected with high repeatability independently in each image are such features. Many detectors and descriptors are designed to be invariant to photometric (due to different sensors and lighting) and affine geometric transformations (due to different viewpoints). In recent years, a new approach of using large datasets of image patch correspondences is established, \cite{Snavely2008, ZagoruykoK15}. However, when very few, even only $2$ {\em structured} (having homogeneous regions with distinctive boundaries) images are available, e.~g.~in some scientific applications \cite{Ranguelova2016AICCSA}, deep learning is not applicable.

The Maximally Stable Extremal Regions (MSER) has become the standard in the field, \cite{ Matas2002BMVC}. It is often used in combination with a histogram-of-gradients type descriptor such as Scale-invariant Feature Transform (SIFT) or Speeded-Up Robust Features (SURF), \cite{Bay2008}, computed from image intensities around the cetroids of the MSER regions. We argue that using the shape and moment information of the  regions encoded by a {\em Shape and Moment Invariants (SMI)} descriptor is beneficial, compared to image intensities around the region's centroid. Figure \ref{fig:intro1} illustrates two cases of image pairs, one depicting the same scene and the other- not, when SMI outperforms SURF applied on pre-detected MSER regions.

\section{Related work}

\paragraph{Salient region detectors}
A comparative performance evaluation of many region detectors have concluded that the {\em Maximally Stable Extremal Regions (MSER)} is the best performing region detector for structured scenes, \cite{Mikolajczyk:2005, Matas2002BMVC}. MSER has become the de-facto standard in the field: it has been implemented as part of MATLAB, OpenCV, VLFeat, etc. However, despite its success, the detector has several drawbacks: it is sensitive to image blur; it produces nested and redundant regions, and its performance degrades with the increase of image resolution. The Data-driven Morphology Salient Regions Detector (DMSR) have been demonstrated to outperform MSER in the case of those transformations, \cite{Ranguelova2016AICCSA}. Here, we propose to use a Binary detector (BIN) using the data-driven binarization explained in \cite{Ranguelova2016AICCSA}, with either all or only regions with large area ($A_{reg.} \ge f_A.A_{Im.}$) are used.

\paragraph{Region descriptors}
{\em State of the art in region descriptor}
Moment invariants are a group of efficient invariant object descriptors. Flusser et al. introduced a general framework for the derivation of Affine Moment Invariants (AMIs) using graph representation \cite{FLUSSER1993167, SukF04, Flusser09a}.

\paragraph{Detector-descriptor combination}
Research has been performed not only to determine the best region detector and descriptor, but also the best combination detector - descriptor.
For example, the conclusion in \cite{DahlAP11} is that the best combination is DOG or MSER detector and SIFT or DAISY descriptors. The SURF descriptor was not in the list of compared  descriptors.

\section{Image matching with Shape and Moment Invariant descriptor}
We propose a set of several Shape and Moment Invariants (SMI) to encode each salient region into a feature vector (descriptor) used for the region matching. The SMI descriptor contains two parts: {\em simple shape invariants}  and {\em moment invariants} $SMI_i = \{S_i, M_i\}$.

\paragraph{Simple shape invariants}
A binary shape of a region $R_i$ can be described by a set of simple properties defined over the original shape or the equivalent up to the second order moments ellipse $E_i$. These properties are: the region's area $a_i$, the area of the region's convex hull $a^c_i$, the length of the major and minor axes of $E_i$, $\mu_i$ and $\nu_i$ and the distance between the foci of the ellipse $\phi_i$. From these basic properties, a set of shape affine invariants are defined in Table \ref{tab:ssi}.   

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l||l|l|}
\hline
Invariant & Definition & Description\\
\hline
\hline
Relative Area & $\tilde{a}_i = {a_i}/{A}$ & region's area normalized by the image area $A$\\
\hline
Ratio Axes Lengths & $r_i = {\nu_i}/{\mu_i}$& ratio between $E_i$ minor and major axes lengths\\
%\hline
%Orientation & $o_i = \theta_i$& angle between the major axis and the $x$-axis of $E_i$ \\
\hline
Eccentricity &$e_i = \phi_i/\mu_i$& $e_i \in [0,1]$ (0 is a circle, 1 is a line segment.)\\
\hline
Solidity & $s_i = {a_i}/{a_i^c} $ & proportion of the convex hull pixels, that are also in the region. \\
\hline
\end{tabular}
\end{center}
\vspace{-20pt}
\caption{Simple shape invariants.} \label{tab:ssi}
  \vspace{-10pt}
\end{table}
The simple shape invariants part of $SMI_i$ is then $S_i = \{\tilde{a}_i, r_i, e_i, s_i\}$.

\paragraph{Affine Moment Invariants}
 
If $f(x,y)$ is a real-valued image with $N$ points, the AMI functional is defined by
\begin{equation}
I(f) = \int_{-\infty}^{\infty} \prod_{k,j=1}^{N}C_{kj}^{n_{kj}} . \prod_{l=1}^{N}f(x_l, y_l)dx_ldy_l,
\end{equation}
where $n_{kj}$ are non-negative integers, $C_{kj} =x_ky_j - x_jy_k$ is the cross-product (graph edge) of points (nodes) $(x_k, y_k)$ and $(x_j, y_j)$, \cite{SukF04}. For full details of the AMI's theory the reader is referred to \cite{Flusser09a}.
We use the set of $16$ irreducible AMIs of $N=4$th order as implemented by the authors in an open source MATLAB software \cite{UTIAcode}. The AMI part of $SMI_i$ is $M_i = \{m_{i1}, \ldots, m_{i16}\}$. 

Hence, the final descriptor for the $i$-th region is a $20$ element feature vector $SMI_i = \{\tilde{a}_i, r_i, e_i, s_i, m_{i1}, \ldots, m_{i16}\}$. 

\paragraph{Matching}

Lets $\{SMI^1_i\}, i= 1,\ldots, n_1$ and $\{SMI^2_j\}, j= 1,\ldots, n_2$ be the $n_1 \times 20$ and $n_2 \times 20$ matrices with rows the SMI descriptors for the $n_1$ and $n_2$ regions detected via MSER or BIN (all/largest) detector in the pair of images to compare. % We use \texttt{matchFeatures} MATLAB CVS Toolbox function, \cite{matchFeaturesDoc}, to 
We compare exhaustively every pair of local SMI descriptors $SMI^1_i$ and $SMI^2_j$ with Sum of square differences metric. The matching threshold for selection of the strongest matches is $mt$, the max ratio threshold for rejecting ambiguous matches is $mr$, the confidence of a match is $mc$ and only unique matches are considered.
After matching of all descriptor pairs, we select the top quality matches above a matching cost threshold $ct$. From those, we estimate in $it$iterations the affine transformation ${\tilde T}$ between the two sets of points being the centroids of the two matching regions sets as average of $nr$ runs with allowed max point distance $md$. The two images are then transformed $J2 = I1 . {\tilde T}$, $J1 = I2 . {\tilde T}^{-1}$ and a correlation ($cor[X,Y] = cov[X,Y]/ \sqrt{var[X] var[Y]}$) between the original and transformed images is used for confirmation of a true match. If the average correlation similarity between both images and their transformed versions $(cor[I1, J1]+cor[I2, J2])/2$ is above a similarity threshold $st$, we declare the original image pair $<I1, I2>$ to be depicting (partially) the same scene.

\section{Performance Evaluation}

VGG dataset, \cite{Mikolajczyk:2005}.
OxFrei dataset, \cite{Ranguelova2016AICCSA}.
Used parameters: $mt=mr=1$, $f_A=2e-3$ (for BIN largest), $it=1000$, $nr=10$, $mc=95$, $md=8px$, $ct=0.025$, $st=0.25$.
\subsection{VGG dataset}

%% comment line

The performance results on the VGG dataset are summarized in Table \ref{tab:vgg}.
\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l||c|c|c|c|c|c|c|}

\hline
Det. + descr. & TP & TN & FP & FN & Acc. &Prec. &Recall\\
\hline
\hline
MSER + SURF & $128$ & $428$ &$4$ & $16$ & $0.965$ & $0.969$ & $0.889$\\
\hline
MSER + \bf{SMI} & $122$ &$430$  &$2$  &$22$  &$0.958$  & $0.98$ & $0.847$\\
\hline
BIN + SURF & $122$ & $426$ & $6$ & $22$ & $0.951$ & $0.953$ &$0.847$\\
\hline
BIN (All) + \bf{SMI} &$84$  &$432$  &$0$  &$60$ &$0.89$  & $1$ &$0.58$ \\
\hline
BIN (Largest) + \bf{SMI} &$112$  &$424$  &$8$  &$32$ &$0.93$  & $0.93$ &$0.77$ \\
\hline
\end{tabular}
\end{center}
\vspace{-20pt}
\caption{Performance of salient region detectors and descriptors on the VGG dataset.} \label{tab:vgg}
  \vspace{-10pt}
\end{table}

\subsection{OxFrei dataset}

The performance results on the OxFrei dataset are summarized in Table \ref{tab:oxfrei}.
\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l||c|c|c|c|c|c|c|}

\hline
Det. + descr. & TP & TN & FP & FN & Acc. &Prec. &Recall\\
\hline
\hline
MSER + SURF & $3309$ & $28848$ & $2904$ & $660$ & $0.90$ & $0.53$ & $0.83$\\
\hline
MSER + \bf{SMI} & $2957$ & $31162$ & $590$ & $1012$ & $0.95$ &$0.83$ & $0.74$\\
\hline
BIN + SURF & $2513$ & $28198$ & $3554$ & $1456$ & $0.85$ &$0.41$ & $0.63$\\
\hline
BIN (All) + \bf{SMI}  & $1275$ & $31298$ & $454$ & $2694$ & $0.91$ &$0.73$ & $0.32$\\
\hline
BIN (Largest) + \bf{SMI}  & $2079$& $28474$ & $3278$ & $1890$ & $0.85$ & $0.38$ & $0.52$\\
\hline
\end{tabular}
\end{center}
\vspace{-20pt}
\caption{Performance of salient region detectors and descriptors on the OxFrei dataset.} \label{tab:oxfrei}
  \vspace{-10pt}
\end{table}

\section{Conclusion}


%\section*{Acknowledgments}

%%\subsection{Bibliographic references}
%%References in a bib file format (e.g. imvip2017.bib given in the template) can be inserted using bibtex along with
%%\LaTeX\xspace/pdflatex (e.g.  \cite{hartley} or  \cite{jain, goodfellow}). 


%%%%%%%%%%%%%%%%%%%%%%%%
%\appendix

%\section{VGG dataset matching results }



%\section{OxFrei dataset matching results }



\bibliographystyle{apalike}

\bibliography{imvip2017}


\end{document}

