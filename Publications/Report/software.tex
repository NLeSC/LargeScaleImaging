\section{Software}
\label{sec:soft}

The saliency detection, dataset annotation and recognition tools developed by the researchers are often made available to the community.

\subsection{Saliency}

\subsubsection{Saliency Map Algorithm} \label{subsec:salmap}
The algorithms for the classical Itti  \cite{Itti_Koch01nrn} saliency maps as well as the GBVS maps \cite{Harel07graph-basedvisual} are available as MATLAB source code at the \href{subsec:salmap}{Saliency Map Algorithm page}, \cite{salmap_soft}.

\subsubsection{SaliencyToolbox}\label{subsec:saltool}
The \href{http://saliencytoolbox.net/index.html}{SaliencyToolbox} \cite{saltool_soft} is a collection of Matlab functions and scripts for computing the saliency map for an image, for determining the extent of a proto-object, and for serially scanning the image with the focus of attention. 

\subsubsection{Frequency-tuned Saliency}
The code used in the CVPR 2009 paper ``Frequency-tuned Salient Region Detection'' (\cite{LCAV-CONF-2009-012}) is accessible through the online presentation of the work at \cite{achantaCVPR09}.

\subsubsection{FastSalience}\label{soft:fastsal:subsec}
One of the few software tools which are not implemented in MATLAB is part of the \href{http://mplab.ucsd.edu/~nick/NMPT/main.html}{Nick's Machine Perception Toolbox (NMPT)}, \cite{nmpt_soft}.\href{http://mplab.ucsd.edu/~nick/NMPT/class_fast_salience.html}{FastSalience} is an implementation of the ``Fast Salience Using Natural-statistics'' algorithm from Butko et al., \cite{ButkoZCM08}.

\subsection{Salient regions}\label{soft:salreg:sec}

{The software used for performance evaluation and comparison of salient region detectors and descriptors \cite{Mikolajczyk:2005} as well as the test datasets (\ref{sec:salregdb}) can be found online from the \href{http://www.robots.ox.ac.uk/~vgg/research/affine/index.html}{Oxford Vision Group page} (\cite{vgg_soft_data}). The comparison scripts are MATLAB code, while some of the detectors (IBR,EBR, MSER) are available only as executables. Specific detector and descriptor software is given below.

\subsubsection{Detectors}\label{soft:salregdet:subsec}

The most popular affine covariant region detector {\em Maximally Stable Extremal Regions MSER} (\cite{Matas2002BMVC}) has several available implementations, most popular of which are:
\begin{enumerate}
\item{\bf MATLAB Computer Vision Systems Toolbox}. The MSER detector is implemented as a function \href{http://nl.mathworks.com/help/vision/ref/detectmserfeatures.html}{\textsf{detectMSERFeatures}} in the MATLAB CVS Toolbox since release R2012a. 
\item{\bf OpenCV}. There is MSER class descendant from the \textsf{FeatureDetector} class in the \href{http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html}{Feature Detection and Description} functionality in the open source OpenCV library.
\item{\bf Vision Lab Features Library (VLFeat)},\cite{vlfeat_soft}. The \href{http://www.vlfeat.org/api/mser.html}{MSER} is part of the VLFeat library.
\end{enumerate}
The software for the  {\em Maximally stable color region (MSCR)} detector, \cite{Forssen07}, is available at the Forssen's \href{http://www.cs.ubc.ca/~perfo/mscr/}{homepage} \cite{forssen07_soft}.
No code for the {\em Maximally Stable Volumes (MSVs)}, \cite{DonoserB06} and for the {\em Structure-Guided Salient Region detector (SGSR)}, \cite{Fan08} or the enhanced MSER with Canny,\cite{Wang14}  was found online.
The code for the  {\em Morphology based Stable Salient Regions (MSSR) } detector, Ranguelova et al. \cite{RangMSSR06, RangHumpb06} is available in the (for now private) \href{https://github.com/NLeSC/LargeScaleImaging/tree/master/Software}{git NLeSc repository}.

\subsubsection{Descriptors}

There are numerous implementations of the {\em SIFT} descriptor, \cite{Lowe:2004}:
\begin{enumerate}
\item{\bf Lowe's own executable} is available at \href{http://www.cs.ubc.ca/~lowe/keypoints/}{Demo Software SIFT Keypoint page}, \cite{lowe_sift_soft}.
\item{\bf Vision Lab Features Library (VLFeat)},\cite{vlfeat_soft}. The \href{http://www.vlfeat.org/api/sift.html}{SIFT} is part of the VLFeat library. It includes implementations of both the SIFT detector and descriptor.
\item{\bf OpenCV}. This \href{http://docs.opencv.org/master/da/df5/tutorial_py_sift_intro.html}{OpenCV tutorial} explains the SIFT Python API in OpenCV.
\item{\bf GPU} implementation of SIFT, \cite{Sinha06gpu-basedvideo} is available at \href{http://cs.unc.edu/~ccwu/siftgpu/}{SiftGPU}, \cite{sift_gpu_soft}. 
\end{enumerate}

The related HoG detector,{\em SURF}  is implemented as a function \href{http://nl.mathworks.com/help/vision/ref/detectsurffeatures.html}{\textsf{detectSURFFeatures}} in the MATLAB CVS Toolbox since release R2011b. The \href{http://docs.opencv.org/master/df/dd2/tutorial_py_surf_intro.html}{SURF Tutorial} describes the SURF Python API in OpenCV.

Many {\em binary descriptors} have also become standard in many Computer vision software libraries:
\begin{enumerate}
\item{\bf MATLAB's Computer Vision Systems (CSV) Toolbox} contains many feature detectors and their descriptors (Harris, FAST, FREAK, BRISK in addition to SURF and MSER) and possibility to match and display matched features. The \href{http://nl.mathworks.com/help/vision/feature-detection-extraction-and-matching.html}{Feature Detection and Extraction functionality} contains binary descriptors since release R2013a.
\item{\bf} {\bf VLFeat Library} supports three local descriptors- SIFT, LIOP and raw patches (from which any other descriptor can be computed). Their use with the  detectors is described in the \href{http://www.vlfeat.org/overview/covdet.html}{Covariant feature detectors tutorial}. 
\item{\bf} {\bf OpenCV library} contains \href{http://docs.opencv.org/modules/features2d/doc/common_interfaces_of_descriptor_extractors.html?highlight=descriptorextractor#descriptorextractor}{\textsf{DescriptorExtractor class}} which supports the following descriptors-SIFT, SURF, BRIEF, BRISK, ORB and FREAK. It supports also descriptor matchers.
\end{enumerate}

For the more recent descriptors authors often publish code along with their paper, e.g. the code for the {\em BOLD}, \cite{Balntas_2015_CVPR} can be obtained \href{http://vbalnt.io/projects/bold/}{online}.

\subsection{Deep Learning}
With the excellent performance of CNNs on the ImageNet classification dataset and many other recognition tasks, there is a boom of development of software tools implementing deep learning and CNNs. 
The tools are often free and open source. At \href{http://deeplearning.net/software_links/}{DeepLearning.net} there is an extensive list of such packages/libraries. Here, only the most popular are presented:
\subsubsection{Caffe}
Caffe (\cite{caffe_soft}) is BSD2-Clause license modular framework for deep learning developed by the Berkeley Vision and Learning Center (BVLC). The framework is a C++ library with Python and MATLAB bindings fr training and deploying general-purpose CNNs and other deep models on commodity architectures. It is a very popular framework, both in academia and industry due to its speed performance- it can process $60M$ images per day with single NVIDIA K40 GPU. There is a large community of user and user groups and contributors on GitHub. A technical report for Caffe can be found at it's git repository: \url{https://github.com/BVLC/Caffe/}. It is the most popular open source project on computer vision and deep learning.  
\subsubsection{Torch7}
Torch (\cite{torch_soft}) is a scientific computing framework with wide support for machine learning algorithms. It is efficient due to the underlying C/CUDA implementations. It has interfaces to C, via LuaJIT, linear algebra routines, neural networks and numeric optimization routines. It runs on Mac OS X and Ubuntu 12+. There is a large community of contributors and users and the developers and maintainers are from Facebook AI Research, Google DeepMind, Twitter etc. 
\subsubsection{Theano}
Theano (\cite{theano_soft}) is a Python library allowing you definition, optimization, and evaluation of mathematical expressions involving multi-dimensional arrays efficiently. It supports transparent usage of GPU. \cite{bergstra+al:2010-scipy} and \cite{Bastien-Theano-2012} are the initial publications about the library with a new academic publication coming up nearly every year. Many DeepLearning tutorials are based on Theano. The official Theano tutorial could be found at \url{http://deeplearning.net/software/theano/tutorial/}.
\subsubsection{MATLAB Toolboxes}
{\bf DeepLearnToolbox}(\cite{deeplearntoolbox_soft})is a Matlab/Octave toolbox for deep learning. Includes Deep Belief Nets, Stacked Autoencoders, Convolutional Neural Nets, Convolutional Autoencoders and vanilla Neural Nets. Each method has examples to help the starting process.\\
{\bf MatConvNet} (\cite{matconvnet_soft}) is a MATLAB toolbox implementing Convolutional Neural Networks (CNNs) for computer vision applications. It is part of the VLFeat suite (\cite{vlfeat_soft}), which contains also salient feature extraction (see section \ref{soft:salregdet:subsec}). MatConvNet is described in \cite{matconvnet_paper}.\\
 There are many other MATLAB software which provide CNN implementations, some can be found at the \href{http://www.mathworks.com/matlabcentral/fileexchange/24291-cnn-convolutional-neural-network-class}{MATLAB FileExchange}.

\subsubsection{Deeplearning4j}
Deeplearning4j 

\subsubsection{Dataset annotation}\label{subsec:dbannot}
A common problem of using Deep Learning is the need for having large annotated datasets (though also unsupervised approaches exist). This is an issue for large-scale imaging problems. Some software has been developed to tackle the issue.

{\bf LabelMe} is a WEB-based image annotation tool that allows researchers to label images and share the annotations with the world. The images can be organized into collections, which can be nested. Images can also be uploaded into the system and shared.

The LabelMe MATLAB toolbox is used for interaction with the images and annotations in the LabelMe dataset \ref{subsec:obj_scene_db}. The tool is described in this paper
\cite{Russell2008}. The toolbox also exists in 3D version, LabelMe3D which is described in \cite{Russell2009}. There is also a mobile App version and instructions how could the labeling be outsourced using the Amazon Mechanical Turk.

\subsection{Distributed software for CV}
sensstorm...