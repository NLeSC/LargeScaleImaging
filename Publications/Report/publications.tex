\section{Publications}
\label{sec:pubs}


\subsection{Saliency}

In \cite{LiuCVPR2007} the salient object detection is formulated as image segmentation problem. The object is separated from the background on the basis of several features including multi-scale contrast, center-surround histogram and colour spatial distribution for the object description on several levels- locally, regionally and globally. The multi-scale contrast is the local feature, the center-surround histogram is the regional feature and the colour spatial histogram- the global. These features are illustrated on Figure \ref{fig:sal_feat_liu07}.
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.95\textwidth]{fig/SalientFeatures_Liu2007}
\end{center}
\caption{Examples of salient features. From leftto right: input image, multi-scale contrast, center-surround histogram, colour spatial distribution and binary salient mask by CRF.}
\label{fig:sal_feat_liu07}
\end{figure}
A conditional Random Field is trained on these features. 
For the purposes of this research the autors have compiled a large-scale database, MSRA (\cite{msra_db}), presented in section \ref{subsec:msra}. The database is publically available, while the software is not. The proposed methods compared to two other algorithms ``FG" (fuzzy growing) and ``SM" (salient model as computed by the SalientToolbox, described in section \ref{subsec:saltool}). The authors' tends to produce smaller and more focused bounding boxes.

{\em good for automatic cropping?}
In \cite{LCAV-CONF-2009-012} the authors perform a frequency-domain analysis on five stateof-
the-art saliency methods, and compared the spatial frequency
content retained from the original image, which is
then used in the computation of the saliency maps. This
analysis illustrated that the deficiencies of these techniques
arise from the use of an inappropriate range of spatial frequencies.
Based on this analysis, they presented a frequency-tuned
approach of computing saliency in images using low
level features of color and luminance. The resulting saliency maps are better suited to salient object segmentation, with higher precision and
better recall than the analyzed state-of-the-art techniques.

In \cite{YanCVPR2013} the authors address a fundamental problem in saliency detection, namely, the small-scale background structures, which affect the detection. This problem occurs often in natural images. They propose a hierarchical framwork that infers importance values fromimage layers with different scales. The approach is summarized in Figure \ref{fig:hier_yan13}.

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.95\textwidth]{fig/Hierarchy_Yan13}
\end{center}
\caption{An overview of the hierarchical framework. Three image layers are extracted from the input, and then  saliency cues from each of these layers are computed. They are finally fed into a hierarchical model to get the final results.}
\label{fig:hier_yan13}
\end{figure}

For the purpose of their research the authors made a new database available to the community, the Complex Scene Saliency dataset (CSSD) and the Extended CSSD (ECSSD), described in Section \ref{subsec:cssd}. The executable of their software is also available from the project link (\cite{ecssd_db}), but not the source code. The authors report better performence of their method on MSRA-1000 and (E)CSSD datasets comapred to $11$ other state-of-the-art methods.

\subsection{Salient regions}

Detecting automatically {\em salient}, e.g.  interesting, disctinct, characteristic and repeatably findable regions from an image is a major reserach topic in the area of image {\em feature extraction}. The salient regions are one type of features which can offer useful representation of images along with interest points, edges, ridges etc. Usually the first step is automaticlly extracting salient regions using an salient/interest region {\em detector} follwed by describing each region/patch using a region {\em descriptor}. As a final step, two sets of region descriptors are compared and {\em matched} in order to establish correspondences between $2$ images. The main application areas are wide-baseline stereo matching, panoramas stiching,  and identification of scenes and objects. 

One very important and desired property of such region detection is {\em affine covaiance}.  The affine covaiance property refers to the requirenment that these regions should correspond to the same pre-image for different viewpoints and geometric transformaitons. In the literature that property is often refered to as {\em affine invariance} to these transformations. 
This concept is shown on figure \ref{fig:affreg}. The figure illustrates that an affine salient regions detector has automatically and independantly detected the same pre-image regions on both images. Some detectors provide arbitrarily shaped regions, others detect elliptical regions. For the purpose of comparision, the (equivalent) elliptical regions are usually used and shown.
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.95\textwidth]{fig/AffineRegions}
\end{center}
\caption{Example of affine regions detection. Image2 is affinely transformed version of Image1.}
\label{fig:affreg}
\end{figure}

\subsubsection{Detectors}
A decade ago, a seminal paper by the Visual Geometry Group in Oxford, compared the exsiting affine-covariant region detectors in \cite{Mikolajczyk:2005}. A clear conclusion of this comparative study is the the  {\em  Maximally Stable Extremal Regions (MSER)} detector (\cite{Matas2002BMVC}) is the winner in many of the test scenarios and since then, the MSER detector has become a de-facto standart in the field (for example is now an intergral part of the MATLAB Computer Vision System Toolbox). For common implementations of MSER, the reader is referred to \ref{soft:salreg:sec}.

After this comparative study, several reserachers have propossed improvements to the MSER detector though none of them increased the performance drastically. 
In \cite{Forssen07} an MSER colour extension is proposed. The author calles his detector {\em Maximally stable colour region (MSCR)}. In comparision on the well-known Visual Geometry Group in Oxford test image sets (\cite{vgg_soft_data}) with known homographies to the original MSER detector, the simple colour MSER extension (MSER3) and a colour blob detector, the MSCR performes better in most cases. The executables of the software for MSCR and blob detectors are available at the author's homepage \cite{forssen07_soft}.

The MSER detectorhas been also extended in 3D to {\em Maximally Stable Volumes (MSVs)} in \cite{DonoserB06}. The MSVs have been used to sucessfully segment 3D medical images and paper fiber networks.

In \cite{Fan08} a structure-guided salient region detector (SGSR) is introduced. It is based on entropy-based saliency theory and shows competitive performance.

In \cite{Wang14} another enhancmenet of MSER is proposal, namely with the Canny edge detector. The dilation operator is used on the detected edges to remove ambigous edges, which makes the interest regions more representative. The improved MSER shows better performance than the original MSER in image classification in the bag of words framework, though original comparision of repeatability (\cite{Mikolajczyk:2005}) is not presented. 

In the context of humpback whale identification, Ranguelova et al. \cite{RangMSSR06, RangHumpb06} have proposed {\em Morphology based Stable Salient Regions (MSSR) } detector whcih is not better than MSER on repeatability, but mostly on less number of regions (whcih is important in the matching step) and salient perception. Within the eStep, NLeSc's technology platform, some research is ongoing to improve MSSR. The related code is available in the (for now private) git NLeSc repository \url{https://github.com/NLeSC/LargeScaleImaging/tree/master/Software}.

\subsubsection{Descriptors}
ANother important performance evaluation paper from the Oxford Vision group has compared the salient region descriptors \cite{}. 
\subsubsection{Matching}

\subsection{Convolutional Neural Networks}

Recently, an interesting aricle which compares the matching of salient regions  with CNNs with matching with SIFT descriptor have been published \cite{FischerDB14}. The authors have also recorded a new larger dataset, compared to the only $48$ images in the comparative study paper, coverring larger class of image transformations with more images (see \ref{sec:salregdb}). The goal of the paper is to study the regions/patches descriptors, not to evaluate detectors. For the detection step, the standart MSER detector have been used. The paper concludes that the CNN trained features are consistently better than the SIFT descriptor, for the price of a higher computational cost.